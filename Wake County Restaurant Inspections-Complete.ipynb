{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cary open data analysis - COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(!require(RCurl)) {\n",
    "    install.packages(\"RCurl\", repos = \"http://cran.us.r-project.org\")\n",
    "    library(RCurl)\n",
    "}\n",
    "\n",
    "if(!require(RDSTK)) {\n",
    "    install.packages(\"RDSTK\", repos = \"http://cran.us.r-project.org\")\n",
    "    library(RDSTK)\n",
    "}\n",
    " \n",
    "if(!require(ggplot2)) {\n",
    "    install.packages(\"ggplot2\", repos = \"http://cran.us.r-project.org\")\n",
    "    library(ggplot2)\n",
    "}\n",
    " \n",
    "if(!require(lazyeval)) {\n",
    "    install.packages(\"lazyeval\", repos = \"http://cran.us.r-project.org\")\n",
    "    library(lazyeval)\n",
    "}\n",
    "\n",
    "if(!require(tidyverse)) {\n",
    "    install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n",
    "    library(tidyverse)\n",
    "}\n",
    "\n",
    "if(!require(ggmap)) {\n",
    "    install.packages(\"ggmap\", repos = \"http://cran.us.r-project.org\")\n",
    "    library(ggmap)\n",
    "}\n",
    "print('Finished loading libraries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, let's load some packages that we need in order to perform data processing and visualization in the steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurants <- read.csv(\"http://www.catallaxyservices.com/media/blog/restaurants.csv\", sep=\",\", header=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to take advantage of the Cary open data portal and grab a data set.  Cary has a listing of Wake County restaurant inspections which looked interesting.  The problem is that it has address but no latitude & longitude pairs, so we need to go through a geocoding service to get them.\n",
    "\n",
    "To reduce (significantly) the amount of time necessary to go through a free geocoding service, the geocoded final product is available as **restaurants.csv** and is ready for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Get, geocode, and cleanse data\n",
    "##If you want to run this in your own environment, remove the if(FALSE) block.\n",
    "if(FALSE)\n",
    "{\n",
    "  tbl <- read.csv(\"https://data.townofcary.org/explore/dataset/wake_county_food_inspections/download/?format=csv&timezone=America/New_York&use_labels_for_header=true\", sep=\";\", header=TRUE)\n",
    "  tbl$address.string <- paste(tbl$address, tbl$city.town, tbl$state, tbl$postal_code, sep = \" \")\n",
    "  tbl$lat <- 0\n",
    "  tbl$long <- 0\n",
    "  for(i in 1:nrow(tbl)) {\n",
    "    print(tbl[i,]$address.string)\n",
    "    \n",
    "    tryCatch({\n",
    "      sc <- street2coordinates(tbl[i,]$address.string)\n",
    "      tbl[i,]$lat <- sc[1,]$latitude\n",
    "      tbl[i,]$long <- sc[1,]$longitude}, error=function(e){  })\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are interested in building the original data set on your own, here is the code used to build restaurants.csv.  It took at least a couple of hours to process of all of the restaurants, so my recommendation is to use my pre-generated file.\n",
    "\n",
    "**Your mission, should you choose to accept it:**\n",
    "\n",
    "Generate summary data for this data set.  In the first box, we want to see a summary of results.  In the second box, we want to see the first five rows of the data set.  In the third box, we want to see the last five rows of the data set.  For the final box, we want to focus on restaurant scores and get an understanding of the range of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO:  generate a summary of the data\n",
    "summary(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO:  look at the first five rows of the data set\n",
    "head(restaurants, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO:  look at the last five rows of the data set\n",
    "tail(restaurants, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO:  show a summary of just the restaurant scores.\n",
    "summary(restaurants$score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will hit the Google Maps API and return an image of a specific area, centered around the midpoint of our longitude/latitude pairings.  Zoom is how zoomed in Google Maps is.  Scale takes one of two options for the free version:  1 is low-res and 2 is high-res.\n",
    "\n",
    "**Feel free to modify parameters and play with the resulting map.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wakemap <- get_map(location = c(lon = mean(restaurants$long), \n",
    "                                lat = mean(restaurants$lat)), zoom = 11, \n",
    "                   maptype = \"roadmap\", scale = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet will lay out a heat map of the Wake County area based on the number of restaurant ratings.  It isn't very helpful for us, so we'll want to create different types of graphs to visualize the data a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggmap(wakemap, extent = \"device\") +\n",
    "  geom_density2d(data = restaurants, aes(x=long,y=lat),size = 0.3) +\n",
    "  stat_density2d(data=restaurants, aes(x=long, y=lat, fill=..level.., alpha=..level..), size=0.01, bins=16, geom=\"polygon\") +\n",
    "  scale_fill_gradient(low=\"red\",high=\"green\") +\n",
    "  scale_alpha(range = c(0,0.3), guide=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems we are trying to solve:**\n",
    "1.  Where are the sketchy restaurants (rating of 85 or lower)?\n",
    "2.  Which parts of Wake county have the worst ratings?\n",
    "3.  Zooming into Cary, what do the ratings look like?\n",
    "\n",
    "We will solve each of these problems in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dplyr has a function called \"filter\"\n",
    "# TODO:  create a filter which gets ONLY restaurants with a rating UNDER 85.  Call the resulting data set \"sketchy\"\n",
    "sketchy <- dplyr::filter(restaurants, score < 85)\n",
    "\n",
    "# Once you have sketchy filled out, we will use dplyr to get the number of failures (scores < 85) per lat-long pair.\n",
    "sketchy <- sketchy %>%\n",
    "            dplyr::group_by(lat, long) %>%\n",
    "            dplyr::summarize(failures = n())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We now want to produce a POINT map of the sketchy restaurant locations.  To do this, we start with wakemap\n",
    "# and need to include POINTs.  Let's make the size of each point correspond to the number of failures and \n",
    "# hard-code the alpha channel to 0.1.  If you need help, look up ggplot2 types (specifically relating to POINTs)\n",
    "# TODO:  create a ggmap call which includes points of restaurant failures\n",
    "ggmap(wakemap) +\n",
    "    geom_point(data = sketchy, aes(x = long, y = lat, fill = \"red\", alpha=0.1, size = failures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a map of the restaurants with failed inspections.  Each restaurant is its own point and the size of the point represents how many failed inspections the restaurant had.\n",
    "\n",
    "This is pretty interesting, and leads to the next problem:  what do ratings look like for **areas** of Wake county?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want to group restaurants by longitude and latitude.  Specifically, longitude and latitude at 1 place\n",
    "# after the decimal.  This way, we can get clusters of restaurants and they'll show up on the map more clearly.\n",
    "restgrp <- restaurants\n",
    "# TODO:  round restgrp's lat and long values to 1 place after the decimal\n",
    "restgrp$lat <- round(restgrp$lat, 1)\n",
    "restgrp$long <- round(restgrp$long, 1)\n",
    "\n",
    "# TODO:  use dplyr like in the sketchy example to do the following:\n",
    "# 1)  Filter out any N/A scores\n",
    "# 2)  Group by latitude and longitude\n",
    "# 3)  Create two aggregates:  ratings, which is the number of records; and meanscore, which is the mean of scores\n",
    "restgrp <- restgrp %>%\n",
    "            dplyr::filter(!is.na(score)) %>%\n",
    "            dplyr::group_by(lat, long) %>%\n",
    "            dplyr::summarize(ratings = n(), meanscore = mean(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the above section.  As a hint, look at the sketchy block to see how we grouped and aggregated.  When in doubt, use R's help (?[topic]) to read up on options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO:  Set wakemap to a new map value.  This time, set the zoom value to 10 so you can see the entire region.\n",
    "wakemap <- get_map(location = c(lon = mean(restgrp$long), lat = mean(restgrp$lat)), zoom = 10, maptype = \"roadmap\", scale = 2)\n",
    "\n",
    "# TODO:  fill in ggmap with settings.  We want three function calls:\n",
    "# scale_fill_gradient (to give us a visual cue of restuarants.  Pick good colors for low & high.)\n",
    "# geom_text (to display the meanscore, giving us precise values.  Round meanscore to 1 spot after decimal)\n",
    "# geom_tile (to display blocks of color.  Set alpha = 1)\n",
    "ggmap(wakemap) +\n",
    "  scale_fill_gradient(low=\"black\",high=\"orange\") +\n",
    "  geom_text(data = restgrp, aes(x=long, y=lat, fill = meanscore, label = round(meanscore, 1))) +\n",
    "  geom_tile(data = restgrp, aes(x=long, y=lat, alpha=1, fill=meanscore)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have filled out the above section, you should see a map of the area with blocks and ratings.  You can also see that mean scores don't vary too significantly within the area, but look to be a little lower down on the edges of the map.\n",
    "\n",
    "But let's suppose you wanted to get more details on a specific part of the RTP area.  Let's pick Cary, because that's the origin of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Cary restaurants, we want to go down to 2 spots after the decimal.  This is a nice compromise and should\n",
    "# fit our map size better than prior examples.\n",
    "caryrestgrp <- restaurants\n",
    "\n",
    "# TODO:  round caryrestgrp's lat and long values to 2 places after the decimal.\n",
    "caryrestgrp$lat <- round(caryrestgrp$lat, 2)\n",
    "caryrestgrp$long <- round(caryrestgrp$long, 2)\n",
    "\n",
    "# TODO:  use dplyr like in the sketchy example to do the following:\n",
    "# 1)  Filter out any N/A scores\n",
    "# 2)  Group by latitude and longitude\n",
    "# 3)  Create two aggregates:  ratings, which is the number of records; and meanscore, which is the mean of scores\n",
    "caryrestgrp <- caryrestgrp %>%\n",
    "  dplyr::filter(!is.na(score)) %>%\n",
    "  dplyr::group_by(lat, long) %>%\n",
    "  dplyr::summarize(ratings = n(), meanscore = mean(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now are going to build a new data set to plot on top of the map of Cary.  Optionally, you could filter out any values outside of [-78.85, -78.75] longitude and [35.76, 35.84] latitude.  But in this scenario there aren't too many data points once we've aggregated results (492), so it's not necessary to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will now create a Cary map with a zoom of 13 and longitude and latitude around a fixed point.\n",
    "carymap <- get_map(location = c(lon = -78.8, lat = 35.8), zoom = 13, maptype = \"roadmap\", scale = 2)\n",
    "\n",
    "# TODO:  fill in ggmap with settings.  We want the same function calls as the wakemap example above,\n",
    "# but fill in values from caryrestgrp instead of restgrp.\n",
    "ggmap(carymap) +\n",
    "  scale_fill_gradient(low=\"black\",high=\"orange\") +\n",
    "  geom_text(data = caryrestgrp, aes(x=long, y=lat, fill = meanscore, label = round(meanscore, 1))) +\n",
    "  geom_tile(data = caryrestgrp, aes(x=long, y=lat, alpha=1, fill=meanscore)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final exercise creates a heat map for just the Cary area.\n",
    "\n",
    "**Your mission, should you choose to accept it:**\n",
    "\n",
    "Now that you've gone through and solved several problems around filtering and displaying data, what else can you do?  Maybe focus on another part of town, maybe play around with some of the charting options.  Whatever you want to do, make sure to update the notebook!  Use Insert --> Insert Cell Below to add new cells.  Code blocks are runnble and perform actions, whereas Markdown blocks show text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
